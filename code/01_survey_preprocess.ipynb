{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c529302c",
   "metadata": {},
   "source": [
    "## SPUR Densification Survey- Natural Langugage Processing Project\n",
    "notebook author: Emily Robitschek\n",
    "\n",
    "#### Background information on survey: \n",
    "This survey was conducted by the SPUR group at ETH: https://spur.ethz.ch/\n",
    "\n",
    "#### Hypothesis/Research question: \n",
    "Can we use the open text field responses from densification surveys to infer something about the motivations behind why individuals responded the way they did to the densification survey?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073280f",
   "metadata": {},
   "source": [
    "#### Detailed notes and pre-processing based on preliminary inspection of the corpus\n",
    "Initially, the raw data from the Chicago survey text responses (see Figure 1 for examples) was examined to identify potential caveats and preprocessing steps needed to properly prepare the data for analysis. In the process it was observed that:\n",
    "1)\tResponse length varies greatly, with shorter responses more often (but not always) being \"throw away\" responses that are either somewhat random (e.g. \"Fyfgfx\" or \"Bzsbsnsbsn\") or unrelated to the survey or displaying a sort of bored, uncertain or apathetic attitude (or maybe they were just tired of filling out the survey at that point - the interpretation is difficult). Examples include: \"Idk\", \"Nope\", \"Favor\", \"Nigh\", \"40\", \"I’m not yo I’m not talking to you\".\n",
    "\n",
    "2)\tEven in substantive responses, spelling errors can significantly change the meanings of the responses. For instance, in the case of the response \"Because it would be more far to people that don't have much\") - this person clearly meant \"fair\" not \"far\", and in the case of \"I think the 10 percent is to high of a yearly increase\" - this person clearly meant \"too\" not \"to\". Also, slang words appear quite often within responses so filtering/interpreting those terms will add a potentially challenging element as well. \n",
    "\n",
    "For the variations described in point 1 of the discussion of the raw data, these patterns might be informative in and of themselves if they relate reliably and systematically to preferences for certain densification policies determine from the more quantitative aspects of the survey. These responses could even potentially speak to sentiments like lack of trust or lack of knowledge which are likely to influence policy views. However, the interpretation of such an analysis, especially if no specific words relevant to the policies are mentioned, would be challenging as the response character is confounded by other factors like sampling biases and the difficulty/impossibility of inferring the true motivations behind the response. For example, if someone says \"I don't know\" it is not clear if they don't know which policy to pick or if they don't know what else to say for the text response or if they are simply tired of filling out the survey and want it to be over. For point 2, greater length is not always directly indicative of a more meaningful response but in our case we might address some of the issues of varying response lengths by setting an initial cutoff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5834e",
   "metadata": {},
   "source": [
    "## Stage 1: Pre-processing and analysis of response length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152a4ba",
   "metadata": {},
   "source": [
    "To ensure that the model has the best possible input data and therefore the best chance of generating useful and interpretable outputs in the form of topics and keywords related to densification, quality control and preprocessing was undertaken. Once this was completed, 4886 survey responses remained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import necessary packages: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#graphing/visualization packages: \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347cac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def filter_response_df(response_df, open_text_column, min_char=0):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe for survey responses (response_df) and the column with the open text field of \n",
    "    interest (open_text_column) and a minimum character limit (automatically set at zero for no filtering) \n",
    "    and returns a dataframe with the null responses for that column filtered out and if min_char > 0, also \n",
    "    filters out responses shorter than or equal to the min_char limit.\n",
    "    \"\"\"\n",
    "    #filter na responses\n",
    "    response_df = response_df.dropna(subset=[open_text_column])\n",
    "    #calculate character lengths of all non-NA responses\n",
    "    response_char_length = []\n",
    "    for i in range(0, len(response_df)):\n",
    "        char_length = len(response_df[open_text_column][i])\n",
    "        #if char_length < 10: ## if want to look at some of the responses for short character lengths\n",
    "        #    print(response_df[open_text_column][i])\n",
    "            #print(char_length)\n",
    "        response_char_length.append(char_length)\n",
    "    response_df['response_char_length'] = response_char_length\n",
    "    if min_char > 0: \n",
    "        return response_df[response_df['response_char_length'] > min_char].copy()\n",
    "    else: \n",
    "        return response_df\n",
    "\n",
    "def encode_cat(df, column, ordinal=False): \n",
    "    if ordinal == True: \n",
    "        ord_enc = OrdinalEncoder()\n",
    "        df[('%s_cat' % column)] = ord_enc.fit_transform(df[[column]])\n",
    "    else: \n",
    "        df[column] = df[column].astype('category')\n",
    "        df[('%s_cat' % column)] = df[column].cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030ff97",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e96b4",
   "metadata": {},
   "source": [
    "### Generate dataframe to spell correct for cities besides Chicago all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in survey dataframe\n",
    "filepath = '../../../Data_Emily/Densification_Survey/df_spell_corr.csv'\n",
    "df_to_spell_correct = pd.read_csv(filepath)\n",
    "print(len(df_to_spell_correct))\n",
    "\n",
    "#select only responses from the English-speaking cities \n",
    "df_to_spell_correct = df_to_spell_correct[df_to_spell_correct['city'].isin(['Chicago', 'New York', 'Los Angeles', 'London'])]\n",
    "print(len(df_to_spell_correct))\n",
    "\n",
    "#view column with text response\n",
    "df_to_spell_correct['Q12.6']\n",
    "\n",
    "#read in Chicago responses (already spell corrected prior to the other three cities)\n",
    "chicago_spell_corrected_file = '../../../Data_Emily/Densification_Survey/Chicago_original_spellcor.csv'\n",
    "chicago_sp_corr_df = pd.read_csv(chicago_spell_corrected_file, \n",
    "                                 encoding='latin-1', \n",
    "                                 skiprows=[1,2])\n",
    "\n",
    "#merge data and see how many responses there are per city and what the data looks like\n",
    "df_to_spell_correct = df_to_spell_correct.merge(chicago_sp_corr_df[['ResponseId', 'Q12.6_corrected']], how='left', left_on='ResponseId', right_on='ResponseId')\n",
    "print(df_to_spell_correct.city.value_counts())\n",
    "df_to_spell_correct[['ResponseId', 'Q12.6', 'Q12.6_corrected']].head()\n",
    "\n",
    "#specify an output file to write out respondent id and responses in order to spell correct the responses \n",
    "#for the other three cities\n",
    "\n",
    "#out_file = '../../../Data_Emily/Densification_Survey/df_short_responses_spell_correct.csv'\n",
    "#df_to_spell_correct[['ResponseId', 'Q12.6', 'Q12.6_corrected', 'city']].to_csv(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8920661a",
   "metadata": {},
   "source": [
    "### Read in survey and spell corrected responses to merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in survey dataframe\n",
    "filepath = '../../../Data_Emily/Densification_Survey/df_spell_corr.csv'\n",
    "df_to_spell_correct = pd.read_csv(filepath)\n",
    "print('Number of responses for all 6 cities in the survey: ', len(df_to_spell_correct))\n",
    "\n",
    "#select only responses from the English-speaking cities \n",
    "df_to_spell_correct = df_to_spell_correct[df_to_spell_correct['city'].isin(['Chicago', 'New York', 'Los Angeles', 'London'])]\n",
    "print('Number of responses for the 4 English-speaking cities in the survey: ', len(df_to_spell_correct))\n",
    "\n",
    "## load in spell corrected responses: \n",
    "spellcorrected_file = '../../../Data_Emily/Densification_Survey/df_short_responses_spell_correct_v1.csv'\n",
    "spell_corrected_df = pd.read_csv(spellcorrected_file, encoding='latin-1')\n",
    "\n",
    "#fill the na values with a single letter so they can be included in the response length comparison across respondent characteristics\n",
    "spell_corrected_df = spell_corrected_df.fillna(value='N')  \n",
    "\n",
    "#merge the two dataframes\n",
    "survey_response_df = df_to_spell_correct.merge(spell_corrected_df[['ResponseId', 'Q12.6_corrected']], \n",
    "                                                     how='left', left_on='ResponseId', right_on='ResponseId')\n",
    "\n",
    "#specify column with corrected text\n",
    "subset_col = 'Q12.6_corrected'\n",
    "\n",
    "#run this function without filtering to generete the response_char_length parameter \n",
    "response_df = filter_response_df(survey_response_df, subset_col, min_char=0)\n",
    "response_df = response_df.drop(columns=(['Unnamed: 0'])) # drop extra columns from filtering\n",
    "\n",
    "print('Number of responses after merge and filter: ', len(response_df))\n",
    "response_df.head(10)\n",
    "\n",
    "#save to file: \n",
    "#response_df.to_csv('../../datasets/spur_survey_responses_english_spellcor.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848c47b",
   "metadata": {},
   "source": [
    "### Compute some summary statistics for response length across cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "# Groupby by city\n",
    "city_initial = response_df.groupby(\"city\")\n",
    "\n",
    "city_initial.size().sort_values(ascending=False).plot.bar()\n",
    "plt.xticks(rotation=50)\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Number of responses\")\n",
    "plt.show()\n",
    "\n",
    "# Summary statistic of all countries\n",
    "city_initial['response_char_length'].describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9773ab3",
   "metadata": {},
   "source": [
    "### Correlations of response length and other survey variables\n",
    "Because response length itself could vary based on respondent characteristics, the spearman correlation was computed between the response lengths (NaN responses were counted to have a length of 1 character, to try to account for bias in who even attempted to fill out the text response) and a subset of other metadata columns in the survey, including potential covariates of response length (e.g. age, income, minority status, location) before length filtering and after length filtering. Project location was encoded with a categorical encoder for inclusion. The resulting correlations were sorted in a descending manner for display.  \n",
    "\n",
    "Note: 'Q6.1' is densif_proj_acceptance_preframe, 'Q7.5' is densif_proj_acceptance_postframe, 'Q7.6' is the percieved impact of the project on rent, 'Q7.7' is the percieved impact of the project on social cohesion  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cbbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode some socio-demographic factors as a dummy variable for the correlation analysis:\n",
    "\n",
    "#columns to include from survey\n",
    "cols_to_include = [subset_col, 'frame', 'projectLocation',\n",
    "                   'minority', 'linguistic_minority', 'religious_minority', 'social_class_minority', \n",
    "                   'sexual_orientation_minority', 'ethnic_minority', 'national_minority', 'other_minority', \n",
    "                   'disabled_minority',  'Q3.1', 'Q3.3', 'Q3.5', 'Q3.7', 'Q5.5', 'Q14.1_1', 'Q3.11', 'Q3.16', \n",
    "                   'Q4.1', 'Q5.1', 'Q6.5_3', 'Q6.5_6', 'Q6.5_9', 'Q6.5_10', 'Q6.11_1', 'Q6.15_5', 'Q6.15_6', \n",
    "                   'Q14.3', 'Q14.9', 'age', 'city', 'country', \n",
    "                   'response_char_length', 'Q6.1', 'Q7.5', 'Q7.6', 'Q7.7']\n",
    "\n",
    "\n",
    "#create dictionary for mapping the column names to a readable/interpretable form based on the survey question\n",
    "substantive_colnames_map = {'Q3.1': 'gender', 'Q3.3': 'age_numerical', 'Q3.5': 'income', 'Q3.7': 'citizenship', 'Q3.11': 'exp_housing_discrim',\n",
    "                       'Q3.16': 'city_district', 'Q4.1': 'city_neighborhood', 'Q5.1': 'prof_situation', 'Q5.5': 'education', \n",
    "                       'Q6.5_3': 'fear_forced_out', 'Q6.5_6': 'seen_landlord_pressure', 'Q6.5_9': 'changes_in_community', \n",
    "                       'Q6.5_10': 'seen_renovations', 'Q6.11_1': 'neighborhood_connection', 'Q6.15_5': 'respect_rules', \n",
    "                       'Q6.15_6': 'neighbhorhood_crime', 'Q14.1_1': 'political_left_right', \n",
    "                       'Q14.3': 'env_pollution_impact', 'Q14.9': 'climate_concern'}\n",
    "\n",
    "#create scales to map the likert style variables to a numerical scale (columns specified below)\n",
    "mapping_likert = {'do not agree at all': -2, 'do not agree': -1, 'neutral': 0, 'agree': 1, 'fully agree': 2}\n",
    "mapping_likert_neighborhood_connection = {'not connected at all': -2, 'not very connected': -1, 'neutral': 0, 'somewhat connected': 1, 'strongly connected': 2}\n",
    "mapping_likert_climate_concern = {'Not concerned': -2, 'Rather not concerned': -1, 'Neither': 0, 'Quite concerned': 1, 'Very concerned': 2}\n",
    "\n",
    "#create scale to map the age (categorical)\n",
    "mapping_age = {'55+': 5, '45-54': 4, '35-44': 3, '25-34': 2, '18-24': 1}\n",
    "\n",
    "#specify columns of each variable type\n",
    "likert_cols = ['fear_forced_out', 'seen_landlord_pressure', 'changes_in_community', 'seen_renovations', 'respect_rules', \n",
    "               'neighbhorhood_crime']\n",
    "\n",
    "dummy_cols = ['gender', 'citizenship', 'education', 'exp_housing_discrim', #'city_district', 'city_neighborhood', \n",
    "              'prof_situation', 'city', 'country']\n",
    "\n",
    "response_df = response_df[['ResponseId'] + cols_to_include]\n",
    "response_df = response_df.rename(columns=substantive_colnames_map)\n",
    "\n",
    "#remap some columns\n",
    "for col in likert_cols: \n",
    "    response_df[col] = response_df[col].map(mapping_likert)\n",
    "response_df['climate_concern'] = response_df['climate_concern'].map(mapping_likert_climate_concern)\n",
    "response_df['neighborhood_connection'] = response_df['neighborhood_connection'].map(mapping_likert_neighborhood_connection)\n",
    "response_df['age'] = response_df['age'].map(mapping_age)\n",
    "\n",
    "#also make a version of the dataframe with dummy variables: \n",
    "response_df_w_dummies = pd.get_dummies(response_df, columns=dummy_cols)\n",
    "print(list(response_df.columns))\n",
    "print(list(response_df_w_dummies.columns))\n",
    "response_df_w_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d605311",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = encode_cat(response_df, 'projectLocation', ordinal=False) #encode project location for correlation\n",
    "\n",
    "cols = ['ResponseId', 'Q12.6_corrected', 'frame', 'projectLocation', 'minority', 'linguistic_minority', 'religious_minority', \n",
    "        'social_class_minority', 'sexual_orientation_minority', 'ethnic_minority', 'national_minority', 'other_minority', 'disabled_minority', \n",
    "        'age_numerical', 'income', 'political_left_right', 'city_district', 'city_neighborhood', 'fear_forced_out', 'seen_landlord_pressure', \n",
    "        'changes_in_community', 'seen_renovations', 'neighborhood_connection', 'respect_rules', 'neighbhorhood_crime', 'env_pollution_impact', \n",
    "        'climate_concern', 'age', 'response_char_length', 'gender_Female', 'gender_Male', 'gender_Non-binary', 'gender_Prefer not to say', \n",
    "        'citizenship_Dual citizenship', 'citizenship_EU citizen', 'citizenship_National', 'citizenship_Other', 'citizenship_US Born', 'citizenship_US Naturalization', \n",
    "        'education_Apprenticeship', \"education_Bachelor's degree\", 'education_Doctoral degree', 'education_Higher education entrance qualification', \n",
    "        'education_Higher technical examination', \"education_Master's degree\", 'education_No school certificate', 'education_Other', 'education_Secondary school certificate', \n",
    "        'exp_housing_discrim_Do not know', 'exp_housing_discrim_No', 'exp_housing_discrim_Yes', 'prof_situation_Employed (full-time)', 'prof_situation_Employed (part-time)', \n",
    "        'prof_situation_Homemaker', 'prof_situation_Not employed (unemployed)', 'prof_situation_Not working (disability/illness)', 'prof_situation_Not working (other reason)', \n",
    "        'prof_situation_Not working (retired)', 'prof_situation_Student', 'city_Chicago', 'city_London', 'city_Los Angeles', 'city_New York', 'country_United Kingdom', 'country_United States']\n",
    "df_corr= response_df_w_dummies[cols]\n",
    "\n",
    "#drop variables that are NA for all values\n",
    "df_corr = df_corr.dropna(axis=1, how='all')\n",
    "df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc7c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make heatmap of plot above\n",
    "plt.figure(figsize=(1, 12))\n",
    "corr = df_corr.corr(method='spearman')\n",
    "ax = sns.heatmap(corr[[\"response_char_length\"]].sort_values(by=[\"response_char_length\"], ascending=False),\n",
    "                 yticklabels=True,\n",
    "                 robust=True, \n",
    "                 annot=True, \n",
    "                 cmap=\"YlGnBu\")\n",
    "title = (\"Correlation heatmap of response length and potential covariates\" )\n",
    "plt.title(title)\n",
    "file_name=('../../figures/' + title + ('_v2_feb2022_spearman.png'))\n",
    "plt.savefig((file_name), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0cfef0",
   "metadata": {},
   "source": [
    "### Data exploration: Lengths of responses (non-NA or 1 character length responses) for response length cut-off\n",
    "We can notice that response length varies greatly, with shorter responses more often (but not always) being \"throw away\" responses that are either somewhat random (e.g. \"Fyfgfx\" or \"Bzsbsnsbsn\") or unrelated to the survey or displaying a sort of bored, uncertain or apathetic attitude (or maybe they were just tired of filling out the survey at that point - the interpretation is difficult). Examples include: \"Idk\", \"Nope\", \"Favor\", \"Nigh\", \"40\", \"I’m not yo I’m not talking to you\". Greater response length is not always directly indicative of a more meaningful response but in our case we might address some of the issues of varying response lengths by setting an initial cutoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = filter_response_df(response_df, subset_col, min_char=1) #filter nan and 1-character responses\n",
    "response_df = response_df.reset_index()\n",
    "response_df = response_df.drop(columns=(['index']))  # drop extra column from resetting the index\n",
    "response_df[\"ln_response_char_length\"] = response_df[\"response_char_length\"].apply(lambda x: np.log(x))\n",
    "\n",
    "print(\"There are %d entries for the text field in this dataset\" % (len(response_df)))\n",
    "response_df['response_char_length'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5529fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot distribution of length of responses by city\n",
    "#non-log data\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "sns.histplot(data=response_df, x='response_char_length', bins=70, hue=\"city\", alpha=0.3, element=\"step\")\n",
    "plt.xlabel(\"Character length of short-response for survey\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Histogram of character length of short-response for survey across sites\")\n",
    "plt.title(title)\n",
    "file_name=('../../figures/' + title + ('_v2.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#log data\n",
    "plt.rcParams[\"figure.figsize\"] = (12,4)\n",
    "sns.histplot(data=response_df, x=\"ln_response_char_length\", bins=70, hue=\"city\", alpha=0.3, element=\"step\")\n",
    "plt.xlabel(\"ln(character length of short-response for survey)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Histogram of ln(character length of short-response) across sites\")\n",
    "plt.title(title)\n",
    "file_name=('../../figures/' + title + ('_v2.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#non-log data for shorter responses\n",
    "sns.histplot(data=response_df[response_df['response_char_length'] <40], x='response_char_length', bins=8, hue=\"city\", alpha=0.3, element=\"step\")\n",
    "plt.xlabel(\"Character length of short-response for survey\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Distribution of character length of short-response for responses <40 characters across sites\")\n",
    "plt.title(title)\n",
    "file_name=('../../figures/' + title + ('_v2.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#non-log data catplot\n",
    "g = sns.catplot(x='response_char_length', y=\"city\",\n",
    "                hue=\"city\", \n",
    "                data=response_df,\n",
    "                orient=\"h\", height=6, aspect=2, palette=\"Set3\",\n",
    "                kind=\"violin\", dodge=True, cut=0, bw=.2)\n",
    "\n",
    "plt.xlabel(\"Character length of short-response for survey\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Distribution of character length of short-response for survey across sites\")\n",
    "plt.title(title)\n",
    "file_name=('../../figures/' + title + ('_v2_violins.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "\n",
    "#log data catplot\n",
    "g = sns.catplot(x=\"ln_response_char_length\", y=\"city\",\n",
    "                hue=\"city\", \n",
    "                data=response_df,\n",
    "                orient=\"h\", height=6, aspect=2, palette=\"Set3\",\n",
    "                kind=\"violin\", dodge=True, cut=0, bw=.2)\n",
    "\n",
    "plt.xlabel(\"ln(character length of short-response)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Distribution of ln(character length of short-response) for survey across sites\")\n",
    "plt.title(title)\n",
    "file_name=('../../figures/' + title + ('_v2_violins.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93339a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecad12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out short responses for now of ~15 characters\n",
    "min_char = 15 \n",
    "response_df = filter_response_df(response_df_w_dummies, subset_col, min_char= min_char)  \n",
    "response_df = response_df.reset_index()\n",
    "response_df = response_df.drop(columns=(['index'])) # drop extra column from resetting the index\n",
    "\n",
    "print(\"There are %d entries for the text field with less than %d characters in this dataset\" % (len(response_df), min_char))\n",
    "response_df['response_char_length'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb008b",
   "metadata": {},
   "source": [
    "### make correlation heatmap for data after 15 character minimum to see if response length remains not strongly correlated with other survey variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dffa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1, 12))\n",
    "df_corr = response_df[cols]\n",
    "df_corr = df_corr.dropna(axis=1, how='all')\n",
    "\n",
    "corr = df_corr.corr(method='spearman')\n",
    "ax = sns.heatmap(corr[[\"response_char_length\"]].sort_values(by=[\"response_char_length\"], ascending=False),\n",
    "                 yticklabels=True,\n",
    "                 robust=True, \n",
    "                 annot=True, \n",
    "                 cmap=\"YlGnBu\")\n",
    "title = (\"Correlation heatmap of response length and potential covariates min_char=15\" ) \n",
    "plt.title(title)\n",
    "file_name=('../../figures/' + title + ('_v2_feb2022_spearman.png'))\n",
    "plt.savefig((file_name), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90a44a",
   "metadata": {},
   "source": [
    "### Export dataframe post filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796243ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.read_csv('../../datasets/spur_survey_responses_english_spellcor.txt', sep='\\t')\n",
    "response_df = filter_response_df(response_df, subset_col, min_char= min_char)  \n",
    "response_df = response_df.reset_index()\n",
    "response_df = response_df.drop(columns=(['index'])) # drop extra column from resetting the index\n",
    "#response_df.to_csv('../../datasets/spur_survey_response_filtered_df1.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6fbea9",
   "metadata": {},
   "source": [
    "### Discussion of how the corpus will help answer the research question\n",
    "In addition to the open text field, the survey had many other structured questions to gauge participants responses to and feelings about densification projects and intersecting concerns at the community level (e.g. cost of living) and at a more global level (e.g. climate change concerns). Some examples include: \n",
    "\n",
    "    1) The frame on whether the project was situated in respondent’s own neighborhood/district or somewhere else\n",
    "    2) Q7.5 on general acceptance of such densification projects \n",
    "    (alternatively also Q6.1 which is the same question but was asked before the frame)\n",
    "    3) Q7.6 on the perceived effect of such projects on rent\n",
    "    4) Q7.7 on the perceived effect of such projects on social cohesion & composition within the neighborhood\n",
    "    5) Q14.9 on climate change concern\n",
    "\n",
    "In order to compare and interpret the results of the analysis of the text responses with other key survey elements, a subset of these questions will be used to stratify respondents into subpopulations (e.g. those who always accept densification projects versus those that always reject them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'frame'\n",
    "g = sns.displot(response_df, x=question, hue=question, palette=\"Set3\", shrink=.8)\n",
    "plt.xlabel(question)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Responses for %s (project location)\" % question)\n",
    "plt.title(title)\n",
    "file_name=('../../figures/survey_characteristics_bar/' + title + ('_v1_minchar15_bar.png'))\n",
    "#plt.savefig(file_name, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "question = 'Q6.1'\n",
    "g = sns.displot(response_df, x=question, hue=question, palette=\"Set3\", shrink=.8)\n",
    "plt.xlabel(question)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Responses for %s (acceptance densif. projects before frame)\" % question)\n",
    "plt.title(title)\n",
    "file_name=('../../figures/survey_characteristics_bar/' + title + ('_v1_minchar15_bar.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "question = 'Q7.5'\n",
    "g = sns.displot(response_df, x=question, hue=question, palette=\"Set3\", shrink=.8)\n",
    "plt.xlabel(question)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Responses for %s (acceptance densif. projects after frame)\" % question)\n",
    "plt.title(title)\n",
    "file_name=('../../figures/survey_characteristics_bar/' + title + ('_v1_minchar15_bar.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "question = 'Q7.6'\n",
    "g = sns.displot(response_df, x=question, hue=question, palette=\"Set3\", shrink=.8)\n",
    "plt.xlabel(question)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Responses for %s (perceived effect on rent)\" % question)\n",
    "plt.title(title)\n",
    "file_name=('../../figures/survey_characteristics_bar/' + title + ('_v1_minchar15_bar.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "question = 'Q7.7'\n",
    "g = sns.displot(response_df, x=question, hue=question, palette=\"Set3\", shrink=.8)\n",
    "plt.xlabel(question)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Responses for %s (perceived effect on social cohesion)\" % question)\n",
    "plt.title(title)\n",
    "file_name=('../../figures/survey_characteristics_bar/' + title + ('_v1_minchar15_bar.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "question = 'Q14.9'\n",
    "g = sns.displot(response_df, x=question, hue=question, palette=\"Set3\", shrink=.8)\n",
    "plt.xlabel(question)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Responses for %s (climate change concern)\" % question)\n",
    "plt.title(title)\n",
    "file_name=('../../figures/survey_characteristics_bar/' + title + ('_v1_minchar15_bar.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "question = 'Q14.1_1' #survey question on political views\n",
    "g = sns.displot(response_df, x=question, hue=question, palette=\"Set3\", shrink=.8)\n",
    "plt.xlabel(question)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Frequency\")\n",
    "title = (\"Responses for %s (politcal leaning 0- most left and 7-most right)\" % question)\n",
    "plt.title(title)\n",
    "file_name=('../../figures/survey_characteristics_bar/' + title + ('_v1_minchar15_bar.png'))\n",
    "#plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby by city\n",
    "city = response_df.groupby(\"city\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "city.size().sort_values(ascending=False).plot.bar()\n",
    "plt.xticks(rotation=50)\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Number of responses above threshold\")\n",
    "plt.show()\n",
    "\n",
    "# Summary statistic of all countries\n",
    "city['response_char_length'].describe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see if the dataframe wrote out properly\n",
    "#test = pd.read_csv('../../datasets/spur_survey_response_filtered_df1.txt', sep='\\t')\n",
    "#test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
