{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d6a68c",
   "metadata": {},
   "source": [
    "## SPUR Densification Survey- Natural Langugage Processing Project\n",
    "notebook author: Emily Robitschek\n",
    "\n",
    "#### Background information on survey: \n",
    "This survey was conducted by the SPUR group at ETH: https://spur.ethz.ch/\n",
    "\n",
    "#### Hypothesis/Research question: \n",
    "Can we use the open text field responses from densification surveys to infer something about the motivations behind why individuals responded the way they did to the densification survey?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eae364e",
   "metadata": {},
   "source": [
    "## Stage 2: Exploration of the pre-processed data with word clouds\n",
    "For an initial qualitative look at the questions of whether the words in the text responses vary with some of the survey questions, word clouds were generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0054501",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import necessary packages: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create stopword list:\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_wc = set(stopwords.words('english'))\n",
    "\n",
    "#add some words relevant to my data that don't add to the interpretability of the word cloud\n",
    "stopwords_wc.update([\"proposal\", \"proposals\", \"Thank\", \"Thanks\", \n",
    "                     \"really\", \"survey\", \n",
    "                     \"much\", \"generally\", \"generally\", \"general\", \n",
    "                     \"chose\", \"1\", \"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5137014",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "def make_wordcloud(df, response_col, condition_col, condition, output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc): \n",
    "    \"\"\"Takes in a dataframe (df) with a text response column (response_col) and a column to filter subgroups of responses by \n",
    "    another variable (condition_col) and what condition that variable should be for those responses to be included (condition).\n",
    "    The output directory (output_dir) and figure name (fig_name) and size can be specified, along with what stopword list to use. \n",
    "    If not using any stop words, just make as an empty list. Outputs a word cloud of the top 100 words maximum of the set of \n",
    "    specified test responses\"\"\"\n",
    "    text = \" \".join(response for response in df[df[condition_col]==condition][response_col])\n",
    "    print (\"There are {} words in the combination of all review.\".format(len(text)))\n",
    "    wordcloud = WordCloud(max_words=100, stopwords=stopwords_wc, \n",
    "                          background_color=\"white\", width=width, height=height).generate(text)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    if len(stopwords) != 0:\n",
    "        file_name=(output_dir + fig_name + ('_minus_stops_v1.png')) \n",
    "    else:\n",
    "        file_name=(output_dir + fig_name + ('_w_stops_v1.png')) \n",
    "    plt.savefig((file_name), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "output_dir = '../../figures/wordclouds/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_col = 'Q12.6_corrected' #specify corrected text column\n",
    "wc_df = pd.read_csv('../../datasets/spur_survey_response_filtered_df1.txt', sep='\\t')\n",
    "wc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd79bb5",
   "metadata": {},
   "source": [
    "### Test with one response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = wc_df[subset_col][5]\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b08b85",
   "metadata": {},
   "source": [
    "### Test with overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(response for response in wc_df[subset_col])\n",
    "print (\"There are {} words in the combination of all review.\".format(len(text)))\n",
    "\n",
    "# lower max_font_size, change the maximum number of word and lighten the background (for word cloud):\n",
    "wordcloud = WordCloud(max_words=100, background_color=\"white\", width=1000, height=1000).generate(text)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Save the image in the img folder:\n",
    "#wordcloud.to_file(output_dir + \"all_words.png\")\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords_wc, background_color=\"white\", width=1000, height=1000).generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Save the image in the img folder:\n",
    "#wordcloud.to_file(output_dir + \"all_words_minus_stops.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#city comparisons\n",
    "fig_name = 'words_chicago'\n",
    "make_wordcloud(wc_df, subset_col, 'city', 'Chicago', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'words_london'\n",
    "make_wordcloud(wc_df, subset_col, 'city', 'London', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'words_nyc'\n",
    "make_wordcloud(wc_df, subset_col, 'city', 'New York', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'words_la'\n",
    "make_wordcloud(wc_df, subset_col, 'city', 'Los Angeles', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "'''\n",
    "#climate concern comparisons\n",
    "fig_name = 'very_climate_concerned_14.9'\n",
    "make_wordcloud(wc_df, subset_col, 'Q14.9', 'Very concerned', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'not_climate_concerned_14.9'\n",
    "make_wordcloud(wc_df, subset_col, 'Q14.9', 'Not concerned', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "#frame comparisons\n",
    "fig_name = 'neighborhood_frame'\n",
    "make_wordcloud(wc_df, subset_col, 'frame', 'neighborhood', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'district_frame'\n",
    "make_wordcloud(wc_df, subset_col, 'frame', 'district', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'other_district_frame'\n",
    "make_wordcloud(wc_df, subset_col, 'frame', 'other district', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "#acceptance of densification projects comparisons\n",
    "print(\"ACCEPT BEFORE...\")\n",
    "fig_name = 'always_accept_dens_projects_6.1'\n",
    "make_wordcloud(wc_df, subset_col, 'Q6.1', 'always accept', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "print(\"AFTER...\")\n",
    "fig_name = 'always_accept_dens_projects_7.5'\n",
    "make_wordcloud(wc_df, subset_col, 'Q7.5', 'always accept', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "print(\"REJECT BEFORE...\")\n",
    "fig_name = 'always_reject_dens_projects_6.1'\n",
    "make_wordcloud(wc_df, subset_col, 'Q6.1', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "print(\"AFTER...\")\n",
    "fig_name = 'always_reject_dens_projects_7.5'\n",
    "make_wordcloud(wc_df, subset_col, 'Q7.5', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "#acceptance of densification projects comparisons by city \n",
    "fig_name = 'london_always_reject_dens_projects_7.5'\n",
    "make_wordcloud(wc_df[wc_df['city']=='London'], subset_col, 'Q7.5', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'chicago_always_reject_dens_projects_7.5'\n",
    "make_wordcloud(wc_df[wc_df['city']=='Chicago'], subset_col, 'Q7.5', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'la_always_reject_dens_projects_7.5'\n",
    "make_wordcloud(wc_df[wc_df['city']=='Los Angeles'], subset_col, 'Q7.5', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'nyc_always_reject_dens_projects_7.5'\n",
    "make_wordcloud(wc_df[wc_df['city']=='New York'], subset_col, 'Q7.5', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "#acceptance of densification projects comparisons by frame\n",
    "fig_name = 'neighborhood_frame_always_reject_dens_projects_7.5'\n",
    "make_wordcloud(wc_df[wc_df['frame']=='neighborhood'], subset_col, 'Q7.5', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'other_district_frame_always_reject_dens_projects_7.5'\n",
    "make_wordcloud(wc_df[wc_df['frame']=='other district'], subset_col, 'Q7.5', 'always reject', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "#frame and gender \n",
    "fig_name = 'neighborhood_frame_female_3.1'\n",
    "make_wordcloud(wc_df[wc_df['frame']=='neighborhood'], subset_col, 'Q3.1', 'Female', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'neighborhood_frame_male_3.1'\n",
    "make_wordcloud(wc_df[wc_df['frame']=='neighborhood'], subset_col, 'Q3.1', 'Male', output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "\n",
    "#frame and gender \n",
    "fig_name = 'neighborhood_frame_minority_yes'\n",
    "make_wordcloud(wc_df[wc_df['frame']=='neighborhood'], subset_col, 'minority', 1, output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'neighborhood_frame_male_minority_no'\n",
    "make_wordcloud(wc_df[wc_df['frame']=='neighborhood'], subset_col, 'minority', 0, output_dir, fig_name, width=800, height=800, stopwords=stopwords_wc)\n",
    "'''\n",
    "\n",
    "#minorities and country \n",
    "fig_name = 'london_minority_yes'\n",
    "make_wordcloud(wc_df[wc_df['city']=='London'], subset_col, 'minority', 1, \n",
    "               output_dir, fig_name, width=1600, height=800, stopwords=stopwords_wc)\n",
    "fig_name = 'usa_cities_minority_yes'\n",
    "make_wordcloud(wc_df[wc_df['city'].isin(['Chicago', 'Los Angeles', 'NYC'])], subset_col, 'minority', 1, \n",
    "               output_dir, fig_name, width=1600, height=800, stopwords=stopwords_wc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c6c67",
   "metadata": {},
   "source": [
    "These wordclouds show the top 100 words across all survey responses, and for respondents by city, even recovering the respective city names for each city. Such an approach also hints at potential key differences between survey respondents who for instance would always favor densification projects and those who would always reject them. Upon qualitative inspection, one can notice overlapping concerns in the presence of words like “density”, “increase”, “prefer” and “rent”, in all the subpopulations. As we might expect, there is an enrichment of words with a positive connotation (e.g. “good”, “love”, “yes”, “helpful”, “best”, “benefit”, “great”) for those respondents who would agree to the projects and the appearance of words with a negative or resistant connotation like “already”, “bad”, “dislike” in the responses of those who would reject densification policies.  More specific terms like “crime”, “parking”, “crowded”, “overcrowding” and “overpopulated” also appear in the responses of those who would reject densification policies, which provides some insights into the reasons they might not support them. Therefore, while qualitative and not directly statistically comparable, these word clouds already show the potential for the contents of this text response data to align with existing survey elements (e.g. densification project preference) and to reveal new insights that may not be fully captured in other survey questions (e.g. some of the specific reasons why some participants don’t support densification projects). Some other examples based on climate concern and minority status are also included."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
